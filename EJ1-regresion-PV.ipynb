{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figuras/cabecera.png\" alt=\"Drawing\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 1\n",
    "# Aprendizaje supervisado: Regresión.\n",
    "\n",
    "## *Predicción de generación fotovoltaica para autoconsumo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** predecir la generación fotovoltaica para el día siguiente de un hogar con autoconsumo. Se utilizarán datos históricos de la variable target que queremos predecir (datos históricos de generación fotovoltaica) y de otros atributos (features) que pueden ayudar a predecir modelo, como por ejemplo la irradiancia o temperatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes de empezar:\n",
    "\n",
    "* En el archivo **EJ1-data-pv.csv** se encuentra el conjunto de datos de entrada de este ejercicio (atributos + etiqueta). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cómo crear un modelo de Machine Learning desde cero?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figuras/creacion-modeloML.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importar librerías y datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías\n",
    "import sklearn  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargamos el conjunto de datos de entrada\n",
    "# dataset = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PASO 1: Comprender los datos**\n",
    "\n",
    "<img src=\"figuras/paso1.png\" alt=\"Drawing\" style=\"width: 100px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"figuras/paso1-estadistica.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "### Estadísitica descriptiva\n",
    "\n",
    "Es necesario visualizar y comprender los datos con los que vamos a trabajar, así como conocer sus características. \n",
    "\n",
    "1. ¿Cuántos datos hay? ¿Cuántos atributos hay en los datos?  \n",
    "2. ¿Qué significan?\n",
    "3. ¿Falta algún dato?\n",
    "4. Resumen estadístico del conjunto de datos de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ¿Cuántos datos hay?**   **¿Cuántos atributos hay en los datos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filas x columnas de los datos\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ¿Qué significan?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Observa las primeras 5 filas de datos\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de los datos\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert localhour in datetime\n",
    "dataset['localhour'] = pd.to_datetime(dataset['localhour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ¿Falta algún dato?** Se comprueba si falta algún dato, y de ser así, se realiza el recuento de celdas vacías en cada atributo. En este caso, no faltan  datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si falta algún dato y en qué atributo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Resumen estadístico del conjunto de datos de entrada.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estadístico de los datos\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añado columnas de mes y hora\n",
    "dataset['hora'] = pd.DatetimeIndex(dataset['localhour']).hour\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"figuras/paso1.png\" alt=\"Drawing\" style=\"width: 100px;\"/>\n",
    "\n",
    "<img src=\"figuras/paso1-visualizacion.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "Una manera visual de entender los datos de entrada. \n",
    "\n",
    "1. Boxplots\n",
    "2. Matriz de correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma\n",
    "\n",
    "Respresentación gráfica de cada uno de los atributos en forma de barras, donde la superficie de la barra es proporcional a la frecuencia de los valores representados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograma = dataset.hist(xlabelsize=10, ylabelsize=10, bins=100, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots\n",
    "\n",
    "El boxplot (diagrama de caja) nos permite identificar los valores atípicos y comparar distribuciones. Además, se conoce como se distribuyen el 50% de los valores (dentro de la caja)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_boxplot = dataset.plot(kind='box', subplots=True, layout=(4, 3), figsize=(11, 11),\n",
    "                                 sharex=False, sharey=False, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Matriz de correlación** \n",
    "\n",
    "Tabla de doble entrada de los atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra librería de visualización de datos\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Cálculo de coeficientes de correlación\n",
    "corr = dataset.corr(method='spearman') \n",
    "\n",
    "# Quitar valores repetidos\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "  \n",
    "f, ax = plt.subplots(figsize=(16, 14))\n",
    "#Generar Heat Map,\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", mask=mask)\n",
    "    # xticks\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "    # yticks\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    # plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *PASO 2: Preparar los datos*\n",
    "\n",
    "<img src=\"figuras/paso2.png\" alt=\"Drawing\" style=\"width: 100px;\"/>\n",
    "\n",
    "<img src=\"figuras/paso2-datacleaning.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "En este paso se aplicarán:\n",
    "\n",
    "1. Limpieza de datos (data cleaning)\n",
    "2. Transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Limpieza de datos (data cleaning)**\n",
    "\n",
    "Comprobar si exisiten Nan en los datos de entrada. \n",
    "\n",
    "- Se utiliza el método [fillna] de Pandas.\n",
    "\n",
    "- Más información acerca de cómo imputar valores con [Scikit Learn]\n",
    "\n",
    "[Scikit Learn]: https://scikit-learn.org/stable/modules/impute.html\n",
    "[fillna]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna(method=\"backfill\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos de nuevo que no existe ningún **Nan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si falta algún dato y en qué atributo\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Transformación**. \n",
    "\n",
    "- Eliminar/escalar datos si fuera necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino columnas que no nos interesan\n",
    "dataset.drop(['XXXXXXXXXX'], axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divido los datos en **atributos**: X (features) y **etiquetas**: y (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos X (features); etiquetas y (target)\n",
    "X = dataset.drop(['pvgen'], axis=1) \n",
    "y = dataset['pvgen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atributos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etiquetas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"figuras/paso2.png\" alt=\"Drawing\" style=\"width: 100px;\"/>\n",
    "\n",
    "<img src=\"figuras/paso2-datoscategoricos.png\" alt=\"Drawing\" style=\"width: 750px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"figuras/paso2.png\" alt=\"Drawing\" style=\"width: 100px;\"/>\n",
    "\n",
    "<img src=\"figuras/paso2-escalado.png\" alt=\"Drawing\" style=\"width: 750px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Más información de métodos de escalado y preproceso en [Scikit Learn]\n",
    "\n",
    "[Scikit Learn]: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Escalo los atributos/features. Para este caso de estudio no hará falta.\n",
    "#scaler = MinMaxScaler()\n",
    "#X_df = X.copy()\n",
    "#X_scaled = pd.DataFrame(scaler.fit_transform(X_df))\n",
    "#X_scaled.columns = X_df.columns\n",
    "#X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *PASO 3: Dividir los datos*\n",
    "\n",
    "<img src=\"figuras/paso3.png\" alt=\"Drawing\" style=\"width: 100px;\"/>\n",
    "\n",
    "\n",
    "Se dividen los datos en datos de entreno ``X_train``, ``y_train``, datos de validación ``X_val``, ``y_val`` y datos de test ``X_test``, ``y_test``\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"figuras/split-data.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2  # porcentaje de los datos de entrada que utilizaré para validar el modelo\n",
    "\n",
    "# Divido los datos en datos de entreno, validación y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASO 4:  Construcción y evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La métrica de evaluacion seleccionada es **RMSE y R2**. \n",
    "- Todas las métricas en https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "- Modelos supervisados en Scikit-Learn: https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "num_folds = 5\n",
    "error_metrics = {'neg_root_mean_squared_error', 'r2'}\n",
    "models = {('MLP', MLPRegressor()),('RFR', RandomForestRegressor()),\n",
    "          ('GradBR', GradientBoostingRegressor()), ('AdaB', AdaBoostRegressor()),\n",
    "         ('XGB', xgb.XGBRegressor())}\n",
    "\n",
    "\n",
    "results = [] # guarda los resultados de las métricas de evaluación\n",
    "names = []  # Nombre de cada algoritmo\n",
    "msg = []  # imprime el resumen del método de cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib==3.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es el método de Cross-validation?\n",
    "\n",
    "La [validación cruzada] o cross-validation es una técnica utilizada para evaluar los resultados de un análisis estadístico y garantizar que son independientes de la partición entre datos de entrenamiento y prueba. Consiste en repetir y calcular la media aritmética obtenida de las medidas de evaluación sobre diferentes particiones. Se utiliza en entornos donde el objetivo principal es la predicción y se quiere estimar la precisión de un modelo que se llevará a cabo a la práctica.\n",
    "\n",
    "En [Scikit-learn] se pueden consultar todos los tipos de validación cruzada. \n",
    "\n",
    "[validación cruzada]: https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada\n",
    "\n",
    "[Scikit-learn]: https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"figuras/cross-validation.png\" alt=\"Drawing\" style=\"width: 1300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenan cada uno de los modelos, se guarda su resultado y se comparan gráficamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "# Entreno con validación cruzada\n",
    "for scoring in error_metrics:\n",
    "    print('Métrica de evaluación: ', scoring)\n",
    "    for name, model in models:\n",
    "        print('Modelo ', name)\n",
    "        cross_validation = KFold(n_splits=num_folds, shuffle=False)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=cross_validation, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        resume = (name, cv_results.mean(), cv_results.std())\n",
    "        msg.append(resume)\n",
    "    print(msg)\n",
    "\n",
    "    # Comparar resultados entre algoritmos\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Comparación de algoritmos con métrica de evaluación: %s' %scoring)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel('Modelos candidatos')\n",
    "    ax.set_ylabel('%s' %scoring)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "\n",
    "    results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASO 5:  Ajustar hiperparámetros\n",
    "\n",
    "Pasos para realizar el hiperajuste de los parámetros:\n",
    "* Especificar el modelo (modelos) a ajustar.\n",
    "* Especificar una métrica para optimizar.\n",
    "* Definir los rangos de los parámetros de búsqueda: *params*\n",
    "* Asignar un método de validación: *KFold*\n",
    "* Encontrar los Hiperparámetros con los datos de validación: *X_val*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = GradientBoostingRegressor()\n",
    "scoring='r2'\n",
    "params = {\n",
    "    # Number of trees in random forest\n",
    "    'n_estimators': [500, 800, 1000, 1200],  # default=100\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "     # Maximum number of levels in tree\n",
    "    'max_depth': [2, None],  #deafult = None\n",
    "     # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "\n",
    "# Búsqueda de la mejor combinación de hiperparámetros\n",
    "cross_validation = KFold(n_splits=5, shuffle=False)\n",
    "my_cv = cross_validation.split(X_val)\n",
    "gsearch = GridSearchCV(estimator=modelo, param_grid=params, scoring=scoring, cv=my_cv, verbose=2)\n",
    "gsearch.fit(X_val, y_val)\n",
    "\n",
    "# Imprimo el mejor resultado\n",
    "print(\"Mejor resultado: %f utilizando los siguientes hiperparámetros %s\" % (gsearch.best_score_, gsearch.best_params_))\n",
    "means = gsearch.cv_results_['mean_test_score']\n",
    "stds = gsearch.cv_results_['std_test_score']\n",
    "params = gsearch.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASO 5: Evaluación final del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se realizan las predicciones de generación fotovoltaica.\n",
    "\n",
    "Métricas de evaluación:\n",
    "  * RMSE\n",
    "  * R2\n",
    "\n",
    "    \n",
    "Se entrena ``.fit()`` al modelo con los hiperparámetros óptimos encontrados en el apartado anterior y acto seguido se realizan las predicciones con el método ``.predict()``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo seleccionado con los hyperparámetros óptimos.\n",
    "modelo_final = GradientBoostingRegressor(n_estimators=500, learning_rate=0.01, max_depth=2)\n",
    "modelo_final.fit(X_train,y_train)  # Se entrena al modelo \n",
    "y_predict = modelo_final.predict(X_test)  # Se calculan las predicciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error RMSE de test data\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Graficar resultados obtenidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot y_predict vs y_test\n",
    "\n",
    "x = range(len(y_predict))\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.xlabel('tiempo', size=15)\n",
    "plt.ylabel('Energía producida (kWh)', size=15)\n",
    "plt.plot(x, y_predict, alpha=0.4, color='blue', label='PV predict')\n",
    "plt.plot(x, y_test, alpha=0.4, color='red',  label='PV real')\n",
    "plt.title('Predicción vs Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necesitamos hacer Zoom in!!\n",
    "\n",
    "Si fuera necesario, instalar la librería Plotly ``!pip install plotly``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go  # Importamos la librería de plotly\n",
    "import numpy as np\n",
    "\n",
    "# Convierto y_test en formato numpy array para poder graficarlo con plotly\n",
    "y_test= np.array(y_test)\n",
    "\n",
    "init = list(range(len(y_predict)))\n",
    "y_predict_plot = pd.DataFrame(data=y_predict, index=init, columns=['predict'])\n",
    "y_test_plot = pd.DataFrame(data=y_test, index=init, columns=['test'])\n",
    "\n",
    "\n",
    "# Creamos la figura\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=init, y=y_predict_plot['predict'][init],\n",
    "                    mode='lines',\n",
    "                    name='PV predicción'))\n",
    "fig.add_trace(go.Scatter(x=init, y=y_test_plot['test'][init],\n",
    "                     mode='lines', name='PV real'))\n",
    "\n",
    "\n",
    "# Editamos la figura\n",
    "fig.update_layout(autosize=False,\n",
    "                  width=1000,\n",
    "                    height=500,\n",
    "                    title='Predicción vs Real',\n",
    "                   xaxis_title='Periodos',\n",
    "                   yaxis_title='Energía (kWh)')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features/atributos más importantes \n",
    "\n",
    "¿Cuales son las features que tienen más peso es este ejemplo? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el modelo con joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'dataset\\modelo-final-pv'\n",
    "joblib.dump(modelo_final, filename)  # guardo el modelo\n",
    "\n",
    "modelo_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargo el modelo \n",
    "\n",
    "[Joblib] nos permite guardar nuestro modelo ya entrenado para utilizarlo cuando lo necesitemos. \n",
    "\n",
    "[Joblib]: http://exponentis.es/persistencia-de-modelos-en-python-como-guardar-tu-modelo-entrenado-de-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "# Cargamos el conjunto de datos de entrada\n",
    "dataset_prueba = pd.read_excel('dataset/pv-prueba.xlsx')\n",
    "dataset_prueba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = loaded_model.predict(dataset_prueba)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_real = [-0.01, -0.009, -0.009, -0.008, -0.009, -0.009, -0.009, -0.007, 0.076, 0.259, 0.965,\n",
    "           1.674, 2.106, 3.376, 2.681, 2.127, 3.617, 3.344, 2.223, 0.25, -0.008, -0.009, -0.008, -0.008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot y_predict vs y_test\n",
    "\n",
    "x = range(len(resultados))\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.xlabel('tiempo', size=15)\n",
    "plt.ylabel('Energía producida (kWh)', size=15)\n",
    "plt.plot(x, resultados, alpha=0.4, color='blue', label='PV predict')\n",
    "plt.plot(x, pv_real, alpha=0.4, color='red',  label='PV real')\n",
    "plt.title('Predicción vs Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
