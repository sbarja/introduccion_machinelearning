{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figuras/cabecera.png\" alt=\"Drawing\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 2\n",
    "# Aprendizaje supervisado: Clasificación.\n",
    "\n",
    "## *Clasificación binaria de precios de electricidad en el Mercado Diario*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** Imaginando que estamos a medioados de 2020, predecir en qué horas el precio de la electricidad en el Mercado Diario será elevado, siendo la **clase 0** para valores menores a 40 €, y **clase 1** para valores mayores a 40 €.  Se utilizará el contexto y datos históricos del **2020** de la variable target que queremos clasificar y de otros atributos (features) que pueden ayudar a predecir modelo.\n",
    "\n",
    "\n",
    "### Antes de empezar:\n",
    "\n",
    "* En el archivo **EJ2-data-precios.xlsx** se encuentra el conjunto de datos de entrada de este ejemplo (atributos + etiqueta). \n",
    "* Datos del 2 de enero 2020 al 26 de junio de 2020.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importar librerías y datos**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el conjunto de datos de entrada\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Comprender los datos**\n",
    "\n",
    "Es necesario visualizar y comprender los datos con los que vamos a trabajar, así como conocer sus características. \n",
    "\n",
    "1. ¿Cuántos datos hay? ¿Cuántos atributos hay en los datos?  \n",
    "2. ¿Qué significan?\n",
    "3. ¿Falta algún dato?\n",
    "4. ¿Están balanceadas las etiquetas? \n",
    "4. Resumen estadístico del conjunto de datos de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ¿Cuántos datos hay?**   **¿Cuántos atributos hay en los datos?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filasxcolumnas de los datos\n",
    "dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observa las primeras 5 filas de los datos\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ¿Qué significan?** \n",
    "* ***[Hora, Día, Mes]*** Hora, día y mes de cada una de las observaciones. Son valores enteros *int64*.\n",
    "\n",
    "* ***[Hidraul, Eolica, Ciclocomb, Cogener, Nuclear, Carbon, Biomas]*** se refiere a la energía programada horaria del programa PVP en el mercado diario por tipo de producción del día anterior.  Son valores reales *float*.\n",
    "\n",
    "* ***[Demanda]*** es la totalidad de energía programada en el mercado diario eléctrico en España el día anterior.  Son valores reales *float*.\n",
    "\n",
    "* ***[precio-elect-dia-anterior]*** precio de la electricidad el día anterior. Son valores reales *float*.\n",
    "\n",
    "* ***[MIBGAS-dia-anterior]*** precio del gas natural el día anterior. Son valores reales *float*.\n",
    "\n",
    "* ***[Clases]*** son las etiquetas de precio que queremos predecir. Son valores enteros *int64*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de los datos\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ¿Falta algún dato? De ser así, indica cuántos y en que atributo** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si falta algún dato y en qué atributo\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. ¿Están balanceadas las etiquetas?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si las etiquetas están desvalanceadas\n",
    "balance_clases = dataset['precio'].value_counts()\n",
    "print(balance_clases)\n",
    "\n",
    "# Gráfico del balance de clases\n",
    "balance_clases.plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Resumen estadístico del conjunto de datos de entrada:** La estadística descriptiva recolecta y analiza el conjunto de datos de entrada con el objetivo de describir las características y comportamientos de este conjunto mediante las siguientes medidas resumen: número total de observaciones (count), media (mean), desviación estándar (std), valor mínimo (min), valor máximo (max) y los valores de los diferentes cuartiles (25%, 50%, 75%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos estadísticos de cada uno de los atributos\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Visualizar los datos**\n",
    "\n",
    "Una manera visual de entender los datos de entrada. \n",
    "1. Histograma\n",
    "2. Curva de densidad\n",
    "3. Boxplots\n",
    "4. Matriz de correlación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Histograma**\n",
    "\n",
    "Respresentación gráfica de cada uno de los atributos en forma de barras, donde la superficie de la barra es proporcional a la frecuencia de los valores representados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograma = dataset.hist(xlabelsize=10, ylabelsize=10, bins=50, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Gráfico de densidades**\n",
    "\n",
    "Visualiza la distribución de los datos. Es una variable del histograma, pero elimina el ruido, por lo que son mejores para determinar la forma de distribución de un atributo. Lo spicos del gráfico de densidad ayudan a mostrar dónde los valores se concentran más. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = dataset.plot(kind='kde', x=4, subplots=True, legend=True, layout=(4, 4), figsize=(17, 12), sharex=False,\n",
    "                        fontsize=8, stacked=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Boxplots** \n",
    "\n",
    "El boxplot (diagrama de caja) nos permite identificar los valores atípicos y comparar distribuciones. Además, se conoce como se distribuyen el 50% de los valores (dentro de la caja).\n",
    "\n",
    "* **¿Que atributo llama la atención por sus valores atípicos?**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_boxplot = dataset.plot(kind='box', subplots=True, layout=(4, 4), figsize=(15, 10), sharex=False,\n",
    "                                 sharey=False, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Matriz de correlación** \n",
    "Utilizamos el método de Spearman para evaluar la relación monótona entre dos variables contínuas. \n",
    "\n",
    "Comparación entre método de [Pearson y Spearman]\n",
    "\n",
    "[Pearson y Spearman]: https://support.minitab.com/es-mx/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/correlation-and-covariance/a-comparison-of-the-pearson-and-spearman-correlation-methods/\n",
    "\n",
    "\n",
    "* **¿Qué variable no tiene ninguna correlación con ningún atributo?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Otra librería de visualización de datos\n",
    "import seaborn as sns\n",
    "\n",
    "# Cálculo de coeficientes de correlación\n",
    "corr_matrix = dataset.corr(method='spearman') \n",
    "\n",
    "\n",
    "# Quitar valores repetidos\n",
    "mask = np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "  \n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "#Generar Heat Map,\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\" , mask=mask,)\n",
    "    # xticks\n",
    "plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns);\n",
    "    # yticks\n",
    "plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
    "    # plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No podemos ver la correlación con el precio, debemos pasarlo a numérico *LabelEncoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lab_encoder = LabelEncoder() \n",
    "lab_encoder.fit(dataset['precio'])  \n",
    "print(lab_encoder.classes_)  # Muestra las clases diferentes que hay\n",
    "\n",
    "dataset['precio'] = lab_encoder.transform(dataset['precio'])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace column values 0: menor que 40; 1: mayor que 40. \n",
    "\n",
    "dataset['precio'] = dataset['precio'].map({0:1, 1:0})\n",
    "dataset.to_excel('dataset.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volvemos a mostrar la matriz de correlación con el valor del precio [1 (muy alto), 0 (normal)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de coeficientes de correlación\n",
    "corr_matrix = dataset.corr(method='spearman') \n",
    "\n",
    "\n",
    "# Quitar valores repetidos\n",
    "mask = np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "  \n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "#Generar Heat Map,\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\" , mask=mask,)\n",
    "    # xticks\n",
    "plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns);\n",
    "    # yticks\n",
    "plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
    "    # plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4. Preparar los datos*\n",
    "\n",
    "1. Missing data\n",
    "2. Data cleaning (eliminar outliers).\n",
    "3. LabelEncoding (ya lo hemos hecho)\n",
    "4. Feature engineering\n",
    "5. Transformación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, divido los datos en **atributos**: X (features) y **etiquetas**: y (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos X (features); etiquetas y (target)\n",
    "X = dataset.drop(['precio'], axis=1) \n",
    "y = dataset['precio']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing data**\n",
    "\n",
    "Comprobar si exisiten Nan en los datos de entrada. \n",
    "\n",
    "- Se utiliza el método [fillna] de Pandas.\n",
    "\n",
    "- Más información acerca de cómo imputar valores con [Scikit Learn]\n",
    "\n",
    "[Scikit Learn]: https://scikit-learn.org/stable/modules/impute.html\n",
    "[fillna]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si faltan datos en los atributos\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Relleno los missing values de cada atributo con el valor anterior del atributo. \n",
    "X[\"demanda\"].fillna(method='ffill', inplace=True)\n",
    "X[\"carbon\"].fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si faltan datos en el target\n",
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprueba que no falta ningún valor\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Feature engineering**\n",
    "\n",
    "Utilizando la matriz de correlación, eliminar los atributos con una correlacion cercana a 0 con la etiqueta **\"precio\"**. \n",
    "\n",
    "* **¿Qué atributo(s) se elimana(n)?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino el atributo\n",
    "X.drop(['biomas', 'dia', 'eolica', 'mes'], axis='columns', inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Transformación (escalado)**. \n",
    "\n",
    "* **Escalar los datos utilizando el método de *MinMaxScaler()* dentro del rango [0,1].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = X.copy()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(df_scaled))\n",
    "X_scaled.columns = df_scaled.columns\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *5. Dividir los datos*\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2  # porcentaje de los datos de entrada que utilizaré para validar el modelo\n",
    "\n",
    "# Divido los datos en datos de entreno, validación y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=0,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *6. Construcción y evaluación de modelos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seleccionamos **[balanced_accuracy]** como métrica de evaluación. \n",
    "* Métricas de evaluación disponibles en [Scikit-Learn].\n",
    "\n",
    "\n",
    "[Scikit-Learn]: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "[balanced_accuracy]: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html\n",
    "\n",
    "* Recordar utilizar siempre el mismo random_state para poder comparar resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "num_folds = 15\n",
    "error_metrics = {'balanced_accuracy', 'f1_weighted'}\n",
    "models = { ('LR', LogisticRegression(solver='saga')), \n",
    "          ('LR-weight', LogisticRegression(solver='saga')),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "           ('RF-weight', RandomForestClassifier(class_weight={0:1,1:4})),\n",
    "           ('RF', RandomForestClassifier()), \n",
    "           ('XGB', xgb.XGBClassifier()),\n",
    "          ('XGB-weight', xgb.XGBClassifier(sample_weight=sample_weights_data))\n",
    "         }\n",
    "\n",
    "results = [] # guarda los resultados de las métricas de evaluación\n",
    "names = []  # Nombre de cada algoritmo\n",
    "msg = []  # imprime el resumen del método de cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **¿Cuál obtiene mejores resultados?** \n",
    "* **¿Qué balanced_accuracy obtiene?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Entreno con validación cruzada\n",
    "for scoring in error_metrics:\n",
    "    print('Métrica de evaluación: ', scoring)\n",
    "    for name, model in models:\n",
    "        print('Modelo ', name)\n",
    "        cross_validation = StratifiedKFold(n_splits=num_folds, random_state=0, shuffle=True)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=cross_validation, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        resume = (name, cv_results.mean(), cv_results.std())\n",
    "        msg.append(resume)\n",
    "    print(msg)\n",
    "\n",
    "    # Comparar resultados entre algoritmos\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Comparación de algoritmos con métrica de evaluación: %s' %scoring)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel('Modelos candidatos')\n",
    "    ax.set_ylabel('%s' %scoring)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "\n",
    "    results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *7. Ajustar hiperparámetros*\n",
    "\n",
    "Pasos para realizar el hiperajuste de los parámetros:\n",
    "[XGBClassifier] parámeteros\n",
    "\n",
    "* Métrica para optimizar: *balanced_accuracy*\n",
    "* Definir los rangos de los parámetros de búsqueda: *params*\n",
    "* Entrenar con los datos de validación: *X_val*\n",
    "\n",
    "[XGBClassifier]:https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# XGBOOST\n",
    "modelo = xgb.XGBClassifier()\n",
    "params = {\n",
    "     'booster': ['gbtree', 'dart'], #default=gbtree\n",
    "     'eta': [0.1, 0.3], #default=0.3\n",
    "     # 'max_depth': [3, 6, 8],  #default=6\n",
    "     #'predictor': ['auto', 'gpu_predictor'] # default auto\n",
    " }\n",
    "scoring='balanced_accuracy'\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "my_cv = cross_validation.split(X_val, y_val)\n",
    "gsearch = GridSearchCV(estimator=modelo, param_grid=params, scoring=scoring, cv=my_cv, verbose=2)\n",
    "gsearch.fit(X_val, y_val)\n",
    "\n",
    "print(\"Mejor resultado: %f utilizando los siguientes hiperparámetros %s\" % (gsearch.best_score_, gsearch.best_params_))\n",
    "means = gsearch.cv_results_['mean_test_score']\n",
    "stds = gsearch.cv_results_['std_test_score']\n",
    "params = gsearch.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *8. Evaluación final del modelo*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas de evaluación:\n",
    "  * 1. Matriz de confusión\n",
    "  * 2. Coeficiente de Matthews (MCC)\n",
    "\n",
    "    \n",
    "**Entrena el modelo con los hiperparámetros óptimos encontrados en el apartado anterior y realiza las predicciones.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo_final = RandomForestClassifier(max_features='sqrt', min_samples_split=5,  n_estimators=400, class_weight={0:1,1:5})\n",
    "modelo_final = xgb.XGBClassifier(booster='gbtree', eta=0.3)\n",
    "modelo_final.fit(X_train,y_train)  # Se entrena al modelo RF\n",
    "y_predict = modelo_final.predict(X_test)  # Se calculan las predicciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué atributos tienen más peso en el modelo?** \n",
    "\n",
    "Para el caso del Random Forest, el atributo más importante para predecir los precios es la generación de carbón, seguido de la generación hidráulica y del mes del año. En la matriz de correlación, el atributo carbón era el que tenía más correlación con la variable clase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir la importancia de cada atributo (Solo si Random forest es seleccionado)\n",
    "importancia_atributos = gsearch.best_estimator_.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in gsearch.best_estimator_.estimators_],axis=0)\n",
    "indices = np.argsort(importancia_atributos)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Ranking de importancia de atributos:\")\n",
    "for f in range(X_scaled.shape[1]):\n",
    "    print(\"%d. Atributo %d (%f)\" % (f + 1, indices[f], importancia_atributos[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Matriz de confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_predict)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico no normalizado de la martiz de confusión\n",
    "\n",
    "disp = plot_confusion_matrix(modelo_final, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues, values_format = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Coeficiente de Matthews (MCC)**\n",
    "\n",
    "El MCC utiliza coeficientes de correlación entre -1 y +1. \n",
    "* Coeficiente +1 representa una predicción perfecta\n",
    "* Coeficiente 0 representa una predicción media aleatoria\n",
    "* Coeficiente -1 representa una predicción inversa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_corrcoef(y_test, y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
